{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "\n",
    "def record_to_file(filename, seconds=5):\n",
    "    global FORMAT, CHANNELS, RATE\n",
    "    RECORD_SECONDS = seconds\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "    print(\"Start recording... \", end=\"\")\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)  \n",
    "        frames.append(data)\n",
    "    print(\"recorded\", seconds, \"second(s)\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    wf = wave.open(filename, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import io\n",
    "import google.cloud\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "findat = \"\"\n",
    "def transcribe_file(speech_file):\n",
    "    \"\"\"Transcribe the given audio file.\"\"\"\n",
    "    client = speech.SpeechClient()\n",
    "\n",
    "    with io.open(speech_file, 'rb') as audio_file:\n",
    "        content = audio_file.read()\n",
    "\n",
    "    audio = types.RecognitionAudio(content=content)\n",
    "    config = types.RecognitionConfig(\n",
    "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
    "        sample_rate_hertz=22050,\n",
    "        language_code='en-US')\n",
    "\n",
    "    response = client.recognize(config, audio)\n",
    "    # Each result is for a consecutive portion of the audio. Iterate through\n",
    "    # them to get the transcripts for the entire audio file.\n",
    "    for result in response.results:\n",
    "        # The first alternative is the most likely one for this portion.\n",
    "        # print(u'Transcript: {}'.format(result.alternatives[0].transcript))\n",
    "        data = (u'{}'.format(result.alternatives[0].transcript))\n",
    "    return(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start recording... recorded 5 second(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'hello my name is Joe'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer = \"buffer.wav\"\n",
    "record_to_file(buffer)\n",
    "wf = wave.open(buffer, 'rb')\n",
    "findat = transcribe_file(buffer)\n",
    "transcribe_file(buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola, mi nombre es Joe\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import six\n",
    "\n",
    "from google.cloud import translate\n",
    "translate_client = translate.Client()\n",
    "target = 'es'\n",
    "# Text can also be a sequence of strings, in which case this method\n",
    "# will return a sequence of results for each text.\n",
    "result = translate_client.translate(\n",
    "    findat, target_language=target)\n",
    "\n",
    "trans_text = ((u'{}'.format(result['translatedText'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genders: ['SSML_VOICE_GENDER_UNSPECIFIED', 'MALE', 'FEMALE', 'NEUTRAL']\n",
      "Encodings: ['AUDIO_ENCODING_UNSPECIFIED', 'LINEAR16', 'MP3', 'OGG_OPUS']\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import texttospeech\n",
    "\n",
    "client = texttospeech.TextToSpeechClient()\n",
    "synthesis_input = texttospeech.types.SynthesisInput(text=trans_text)\n",
    "\n",
    "print(\"Genders:\", texttospeech.enums.SsmlVoiceGender._member_names_)\n",
    "voice = texttospeech.types.VoiceSelectionParams(\n",
    "    language_code='en-US',\n",
    "    ssml_gender=texttospeech.enums.SsmlVoiceGender.NEUTRAL)\n",
    "\n",
    "print(\"Encodings:\", texttospeech.enums.AudioEncoding._member_names_)\n",
    "audio_config = texttospeech.types.AudioConfig(audio_encoding=texttospeech.enums.AudioEncoding.MP3)\n",
    "response = client.synthesize_speech(synthesis_input, voice, audio_config)\n",
    "\n",
    "with open('datasets/sound/chord.wav', 'wb') as out:\n",
    "    # Write the response to the output file.\n",
    "    out.write(response.audio_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
