The ability to attribute mental states such as beliefs, intents, desires, emotions, knowledge is what’s commonly referred to as the theory of mind. Using existing and predated technology, we were unable to replicate this behaviour in expert systems. Even reviewing the algorithms that make such machines is impossible for humans to do today. Hence, the requirement of self evaluation arose, and thus project ToMnet was born. 
ToMnet makes up 3 neural networks, each made of little computing components and connections that gain from experience. The very first network finds out the competence of the other machines based upon their previous actions. The 2nd kinds an understanding of their present “beliefs.” And the 3rd takes the output from the other 2 networks and, depending upon the scenario, anticipates the expert systems’ next relocations. The expert system under research study were intelligible objects moving in a virtual space acquiring coloured boxes for points.
ToMnet saw the space from above. In one of the tests, there were 3 “species” of objects : One could not see the surrounding space, one could not remember its current or previous move, and one might both see and keep in mind. 
The blind characters tended to follow along walls, the amnesiacs moved to whatever things was closest, and the 3rd types formed sub goals, tactically getting things in an order to make more points. After some training, ToMnet was not just able to determine a character’s types after simply a couple of actions, however, it properly forecast its future habits.
The last test exposed ToMnet might even comprehend when a character held an incorrect belief, a vital phase in establishing the theory of mind in people and other animals. In this test, one type of character was configured to be near-sighted, when the computer system modified the landscape beyond its vision midway through the video game, ToMnet properly anticipated that it would stick to its initial course more often than better-sighted characters, who were most likely to adjust. The ToMnet is applied to agents behaving in simple gridworld environments, showing that it learns to model random, algorithmic, and deep RL agents from varied populations, and thus it passes classic ToM tasks such as the “Sally-Anne” test of recognising that others can hold false beliefs about the world.


