Neil Rabinowitz, a research scientist at DeepMind in London, and colleagues created a theory of mind neural network called “ToMnet” that would be able to understand the complex computer-generated solutions that human insight cannot penetrate. 
The neural network has its roots on what psychologists call "Theory of Mind". This theory implies that children by the age of four understand the beliefs of others may diverge from reality and that those beliefs can be used to predict the person's future behavior.
This neural network observes other machines to see what it could learn about how these work, ToMnet comprises three neural networks, each made of small computing elements and connections that learn from experience. The first network learns the tendencies of other machines based on their past actions. The second forms an understanding of their current “beliefs.” And the third takes the output from the other two networks and, depending on the situation, predicts the machine’s next moves.
In order to verify the theory, an experiment was conducted where agents from three different species were observed in an 11x11 grid world, the species created based on how sparse its agents' policies were within a space, S(α) each π(i) was drawn from a Dirichlet distribution with concentration parameter α. Each agent had a stochastic policy defined by a fixed vector of action probabilities π(i(·)) =π(i) and the extremes of these agents were πi∼Dir(α=  0.01) at its lowest, where agents in the practical experiment are blind and could only follow around the walls  and πi∼Dir(α= 3) at its highest, these agents would strategically act in order to get more points. The third and middle species could not remember recent steps which means that it would collect a lot of points but not in the most efficient way because the way they would pick the objects that were the closest that not always resulting in the shortest path. 
The architecture that solves the neural network side of the theory has agents that are based on multi-shot reinforcement learning, which means that at each stage they learn a little bit more about their environment, the agent itself will not care about the history of its steps but will use probabilities of possible moves in the current state to decided how to move forward ,the data the main two networks have are these states of the current position and the probability of the next move, which is then passed on to an embedding layer in both networks, which is basically like a look-up table for the agents, the embedding layer will group together similar vectors, and the i-th agent would generally follow a similar pattern making a similar path to its path making small changes after each episode, these are used as an input combined with the current state and will output the next step probability.
At the end of the experiment, ToMnet would not only identify an agents species but would also predict the future behavior of the same.

References:
https://arxiv.org/pdf/1802.07740.pdf
