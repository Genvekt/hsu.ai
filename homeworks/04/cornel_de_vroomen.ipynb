{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "sentences = []\n",
    "lines = open('../../code/datasets/nlp/the old man and the sea.txt').readlines()\n",
    "\n",
    "tokenized_sentences = []\n",
    "for line in lines:\n",
    "    line = line.strip().strip('\"').strip('`').strip(\"'\")\n",
    "    for sentence in re.split('\\.|\\?|!', line):\n",
    "        tokenized_sentences.append(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'ll\", 'be', 'back', 'when', 'I', 'have', 'the', 'sardines']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('sardines', 'NNS')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample sentences\n",
    "print(tokenized_sentences[201])\n",
    "nltk.pos_tag(tokenized_sentences[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('His', 'hope'), ('hope', 'and'), ('and', 'his'), ('his', 'confidence'), ('confidence', 'had'), ('had', 'never'), ('never', 'gone')]\n"
     ]
    }
   ],
   "source": [
    "def get_bigrams(sentence):\n",
    "    bigram = []\n",
    "    for i in range(len(sentence) - 1):\n",
    "        bigram.append((sentence[i], sentence[i + 1]))\n",
    "    return bigram\n",
    "\n",
    "# sample\n",
    "print(get_bigrams(tokenized_sentences[101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrammed_sentences = [get_bigrams(sentence) for sentence in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 2316), ('and', 1259), ('he', 1166), (',', 784), ('of', 540), ('i', 508), ('it', 494), ('to', 454), ('his', 446), ('was', 435), ('a', 397), ('in', 359), ('that', 299), ('fish', 285), ('man', 264), ('old', 248), ('but', 233), ('him', 230), ('not', 217), ('with', 205)]\n",
      "OTHER WAY\n",
      "[('the', 2316), ('and', 1259), ('he', 1166), (',', 784), ('of', 540), ('i', 508), ('it', 494), ('to', 454), ('his', 446), ('was', 435), ('a', 397), ('in', 359), ('that', 299), ('fish', 285), ('man', 264), ('old', 248), ('but', 233), ('him', 230), ('not', 217), ('with', 205)]\n"
     ]
    }
   ],
   "source": [
    "word_map = {}\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        if word.lower() in word_map:\n",
    "            word_map[word.lower()] += 1\n",
    "        else:\n",
    "            word_map[word.lower()] = 1\n",
    "word_map = sorted(word_map.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "top_20 = []\n",
    "for i in range(20):\n",
    "    top_20.append(word_map[i])\n",
    "\n",
    "print(top_20)\n",
    "\n",
    "\n",
    "################ It can be done differently with NLTK: ################\n",
    "all_words = []\n",
    "for sentence in tokenized_sentences:\n",
    "    for word in sentence:\n",
    "        all_words.append(word)\n",
    "fdist = nltk.FreqDist(word.lower() for word in all_words)\n",
    "top_20 = fdist.most_common(20)\n",
    "\n",
    "print(\"OTHER WAY\")\n",
    "print(top_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
