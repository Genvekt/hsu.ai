{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "sentences = []\n",
    "lines = open('../../code/datasets/nlp/the old man and the sea.txt').readlines()\n",
    "\n",
    "tokenized_sentences = []\n",
    "for line in lines:\n",
    "    line = line.strip().strip('\"').strip('`').strip(\"'\")\n",
    "    for sentence in re.split('\\.|\\?|!', line):\n",
    "        tokenized_sentences.append(nltk.word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', \"'ll\", 'be', 'back', 'when', 'I', 'have', 'the', 'sardines']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " (\"'ll\", 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('back', 'RB'),\n",
       " ('when', 'WRB'),\n",
       " ('I', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('sardines', 'NNS')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample sentences\n",
    "print(tokenized_sentences[201])\n",
    "nltk.pos_tag(tokenized_sentences[201])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('his', 'hope'), ('hope', 'and'), ('and', 'his'), ('his', 'confidence'), ('confidence', 'had'), ('had', 'never'), ('never', 'gone')]\n"
     ]
    }
   ],
   "source": [
    "def get_bigrams(sentence):\n",
    "    # TODO write your code for this method\n",
    "    bigrams = []\n",
    "    for line in range(len(sentence)-1):\n",
    "        bigrams.append(((sentence[line]).lower(), (sentence[line+1]).lower()))\n",
    "    return bigrams\n",
    "\n",
    "# sample\n",
    "print(get_bigrams(tokenized_sentences[101]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrammed_sentences = [get_bigrams(sentence) for sentence in tokenized_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO \n",
    "# write your code to extract the most popular words and thier parts of speech\n",
    "# write your code to extract the most popular STEMMED bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 WORDS:  [(2316, 'the'), (1259, 'and'), (1166, 'he'), (784, ','), (540, 'of'), (508, 'i'), (494, 'it'), (454, 'to'), (446, 'his'), (435, 'was'), (397, 'a'), (359, 'in'), (299, 'that'), (285, 'fish'), (264, 'man'), (248, 'old'), (233, 'but'), (230, 'him'), (217, 'not'), (205, 'with')]\n"
     ]
    }
   ],
   "source": [
    "di = dict()\n",
    "for i in tokenized_sentences:\n",
    "    for x in i:\n",
    "        word = x.lower()\n",
    "        if word in di:\n",
    "            di[word] += 1\n",
    "        else:\n",
    "            di[word] = 1\n",
    "    \n",
    "def sortedDict(di):\n",
    "    x = [(di[k], k) for k in di]\n",
    "    x.sort()\n",
    "    x.reverse()\n",
    "    return x\n",
    "\n",
    "print(\"TOP 20 WORDS: \", sortedDict(di)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 20 BIGRAMS:  [(248, 'of the'), (229, 'old man'), (205, 'the old'), (197, 'in the'), (179, \", ''\"), (172, 'and the'), (161, ', he'), (151, 'and he'), (145, 'he thought'), (139, 'the fish'), (107, 'he was'), (100, 'on the'), (96, 'the boy'), (96, 'he said'), (89, \"'' the\"), (88, 'it was'), (87, \"'' he\"), (83, 'the line'), (80, 'he had'), (73, 'the water')]\n"
     ]
    }
   ],
   "source": [
    "di = dict()\n",
    "for i in bigrammed_sentences:\n",
    "    for x in i:\n",
    "        word = x[0] + \" \" + x[1]\n",
    "        if word in di:\n",
    "            di[word] += 1 \n",
    "        else:\n",
    "            di[word] = 1\n",
    "            \n",
    "def sortedDict(di):\n",
    "    x = [(di[k], k) for k in di]\n",
    "    x.sort()\n",
    "    x.reverse()\n",
    "    return x\n",
    "\n",
    "print(\"TOP 20 BIGRAMS: \", sortedDict(di)[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
